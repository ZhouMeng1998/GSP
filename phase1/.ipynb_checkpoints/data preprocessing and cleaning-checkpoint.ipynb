{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d15dffee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Philip\\AppData\\Local\\Temp\\ipykernel_15648\\3010240173.py:11: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv('covid.csv', error_bad_lines=False)\n",
      "b'Skipping line 6: expected 1 fields, saw 2\\nSkipping line 8: expected 1 fields, saw 2\\nSkipping line 9: expected 1 fields, saw 2\\nSkipping line 17: expected 1 fields, saw 3\\nSkipping line 21: expected 1 fields, saw 2\\nSkipping line 25: expected 1 fields, saw 2\\nSkipping line 27: expected 1 fields, saw 3\\nSkipping line 30: expected 1 fields, saw 2\\nSkipping line 31: expected 1 fields, saw 3\\nSkipping line 32: expected 1 fields, saw 4\\nSkipping line 38: expected 1 fields, saw 4\\nSkipping line 39: expected 1 fields, saw 2\\nSkipping line 56: expected 1 fields, saw 2\\nSkipping line 58: expected 1 fields, saw 2\\nSkipping line 64: expected 1 fields, saw 2\\nSkipping line 66: expected 1 fields, saw 2\\nSkipping line 68: expected 1 fields, saw 2\\nSkipping line 70: expected 1 fields, saw 2\\nSkipping line 72: expected 1 fields, saw 2\\nSkipping line 73: expected 1 fields, saw 2\\nSkipping line 80: expected 1 fields, saw 2\\nSkipping line 81: expected 1 fields, saw 2\\nSkipping line 86: expected 1 fields, saw 2\\nSkipping line 91: expected 1 fields, saw 3\\nSkipping line 92: expected 1 fields, saw 4\\nSkipping line 94: expected 1 fields, saw 3\\nSkipping line 96: expected 1 fields, saw 2\\nSkipping line 99: expected 1 fields, saw 2\\nSkipping line 103: expected 1 fields, saw 3\\nSkipping line 104: expected 1 fields, saw 2\\nSkipping line 105: expected 1 fields, saw 2\\nSkipping line 110: expected 1 fields, saw 2\\nSkipping line 111: expected 1 fields, saw 2\\nSkipping line 112: expected 1 fields, saw 3\\nSkipping line 118: expected 1 fields, saw 2\\nSkipping line 122: expected 1 fields, saw 4\\nSkipping line 124: expected 1 fields, saw 3\\nSkipping line 126: expected 1 fields, saw 2\\nSkipping line 136: expected 1 fields, saw 2\\nSkipping line 139: expected 1 fields, saw 5\\nSkipping line 141: expected 1 fields, saw 2\\nSkipping line 149: expected 1 fields, saw 5\\nSkipping line 165: expected 1 fields, saw 2\\nSkipping line 170: expected 1 fields, saw 4\\nSkipping line 172: expected 1 fields, saw 4\\nSkipping line 173: expected 1 fields, saw 2\\nSkipping line 182: expected 1 fields, saw 3\\nSkipping line 185: expected 1 fields, saw 2\\nSkipping line 192: expected 1 fields, saw 4\\nSkipping line 198: expected 1 fields, saw 4\\nSkipping line 199: expected 1 fields, saw 2\\nSkipping line 201: expected 1 fields, saw 2\\nSkipping line 209: expected 1 fields, saw 3\\nSkipping line 214: expected 1 fields, saw 2\\nSkipping line 219: expected 1 fields, saw 3\\nSkipping line 229: expected 1 fields, saw 2\\nSkipping line 231: expected 1 fields, saw 3\\nSkipping line 233: expected 1 fields, saw 2\\nSkipping line 234: expected 1 fields, saw 5\\nSkipping line 237: expected 1 fields, saw 3\\nSkipping line 238: expected 1 fields, saw 2\\nSkipping line 242: expected 1 fields, saw 4\\nSkipping line 245: expected 1 fields, saw 2\\nSkipping line 246: expected 1 fields, saw 2\\nSkipping line 249: expected 1 fields, saw 2\\nSkipping line 250: expected 1 fields, saw 2\\nSkipping line 253: expected 1 fields, saw 2\\nSkipping line 254: expected 1 fields, saw 3\\nSkipping line 256: expected 1 fields, saw 3\\nSkipping line 258: expected 1 fields, saw 3\\nSkipping line 259: expected 1 fields, saw 3\\nSkipping line 268: expected 1 fields, saw 2\\nSkipping line 269: expected 1 fields, saw 2\\nSkipping line 274: expected 1 fields, saw 4\\nSkipping line 276: expected 1 fields, saw 8\\nSkipping line 280: expected 1 fields, saw 4\\nSkipping line 281: expected 1 fields, saw 2\\nSkipping line 284: expected 1 fields, saw 3\\nSkipping line 287: expected 1 fields, saw 2\\nSkipping line 288: expected 1 fields, saw 3\\nSkipping line 290: expected 1 fields, saw 2\\nSkipping line 292: expected 1 fields, saw 5\\nSkipping line 294: expected 1 fields, saw 2\\nSkipping line 301: expected 1 fields, saw 2\\nSkipping line 303: expected 1 fields, saw 2\\nSkipping line 304: expected 1 fields, saw 6\\nSkipping line 309: expected 1 fields, saw 2\\nSkipping line 325: expected 1 fields, saw 4\\nSkipping line 336: expected 1 fields, saw 6\\nSkipping line 338: expected 1 fields, saw 7\\nSkipping line 340: expected 1 fields, saw 2\\nSkipping line 342: expected 1 fields, saw 2\\nSkipping line 350: expected 1 fields, saw 2\\nSkipping line 363: expected 1 fields, saw 2\\nSkipping line 364: expected 1 fields, saw 3\\nSkipping line 367: expected 1 fields, saw 2\\nSkipping line 369: expected 1 fields, saw 2\\nSkipping line 383: expected 1 fields, saw 2\\nSkipping line 386: expected 1 fields, saw 2\\nSkipping line 389: expected 1 fields, saw 2\\nSkipping line 401: expected 1 fields, saw 2\\nSkipping line 404: expected 1 fields, saw 2\\nSkipping line 405: expected 1 fields, saw 2\\nSkipping line 408: expected 1 fields, saw 4\\nSkipping line 412: expected 1 fields, saw 2\\nSkipping line 413: expected 1 fields, saw 3\\nSkipping line 415: expected 1 fields, saw 2\\nSkipping line 418: expected 1 fields, saw 2\\nSkipping line 419: expected 1 fields, saw 3\\nSkipping line 421: expected 1 fields, saw 2\\nSkipping line 424: expected 1 fields, saw 3\\nSkipping line 430: expected 1 fields, saw 3\\nSkipping line 432: expected 1 fields, saw 3\\nSkipping line 433: expected 1 fields, saw 4\\nSkipping line 440: expected 1 fields, saw 3\\nSkipping line 441: expected 1 fields, saw 4\\nSkipping line 442: expected 1 fields, saw 3\\nSkipping line 443: expected 1 fields, saw 6\\nSkipping line 444: expected 1 fields, saw 2\\nSkipping line 448: expected 1 fields, saw 11\\nSkipping line 453: expected 1 fields, saw 3\\nSkipping line 455: expected 1 fields, saw 6\\nSkipping line 458: expected 1 fields, saw 3\\nSkipping line 459: expected 1 fields, saw 8\\nSkipping line 462: expected 1 fields, saw 2\\nSkipping line 467: expected 1 fields, saw 3\\nSkipping line 471: expected 1 fields, saw 2\\nSkipping line 480: expected 1 fields, saw 3\\nSkipping line 482: expected 1 fields, saw 2\\nSkipping line 486: expected 1 fields, saw 6\\nSkipping line 488: expected 1 fields, saw 3\\nSkipping line 490: expected 1 fields, saw 2\\nSkipping line 491: expected 1 fields, saw 3\\nSkipping line 492: expected 1 fields, saw 3\\nSkipping line 493: expected 1 fields, saw 2\\nSkipping line 499: expected 1 fields, saw 3\\nSkipping line 501: expected 1 fields, saw 3\\nSkipping line 502: expected 1 fields, saw 2\\nSkipping line 503: expected 1 fields, saw 2\\nSkipping line 505: expected 1 fields, saw 2\\nSkipping line 507: expected 1 fields, saw 2\\nSkipping line 510: expected 1 fields, saw 2\\nSkipping line 523: expected 1 fields, saw 3\\nSkipping line 525: expected 1 fields, saw 2\\nSkipping line 526: expected 1 fields, saw 2\\nSkipping line 532: expected 1 fields, saw 4\\nSkipping line 533: expected 1 fields, saw 2\\nSkipping line 547: expected 1 fields, saw 3\\nSkipping line 549: expected 1 fields, saw 3\\nSkipping line 557: expected 1 fields, saw 2\\nSkipping line 559: expected 1 fields, saw 2\\nSkipping line 563: expected 1 fields, saw 3\\nSkipping line 564: expected 1 fields, saw 2\\nSkipping line 567: expected 1 fields, saw 2\\nSkipping line 572: expected 1 fields, saw 3\\nSkipping line 578: expected 1 fields, saw 2\\nSkipping line 581: expected 1 fields, saw 2\\nSkipping line 586: expected 1 fields, saw 3\\nSkipping line 587: expected 1 fields, saw 2\\nSkipping line 589: expected 1 fields, saw 2\\nSkipping line 594: expected 1 fields, saw 4\\nSkipping line 599: expected 1 fields, saw 2\\nSkipping line 601: expected 1 fields, saw 4\\nSkipping line 602: expected 1 fields, saw 2\\nSkipping line 607: expected 1 fields, saw 2\\nSkipping line 612: expected 1 fields, saw 4\\nSkipping line 615: expected 1 fields, saw 2\\nSkipping line 616: expected 1 fields, saw 3\\nSkipping line 617: expected 1 fields, saw 3\\nSkipping line 624: expected 1 fields, saw 2\\nSkipping line 625: expected 1 fields, saw 2\\nSkipping line 626: expected 1 fields, saw 3\\nSkipping line 628: expected 1 fields, saw 3\\nSkipping line 630: expected 1 fields, saw 2\\nSkipping line 632: expected 1 fields, saw 3\\nSkipping line 633: expected 1 fields, saw 3\\nSkipping line 637: expected 1 fields, saw 4\\nSkipping line 638: expected 1 fields, saw 3\\nSkipping line 639: expected 1 fields, saw 3\\nSkipping line 642: expected 1 fields, saw 2\\nSkipping line 647: expected 1 fields, saw 3\\nSkipping line 650: expected 1 fields, saw 2\\nSkipping line 655: expected 1 fields, saw 3\\nSkipping line 661: expected 1 fields, saw 3\\nSkipping line 662: expected 1 fields, saw 2\\nSkipping line 667: expected 1 fields, saw 2\\nSkipping line 669: expected 1 fields, saw 2\\nSkipping line 670: expected 1 fields, saw 2\\nSkipping line 671: expected 1 fields, saw 4\\nSkipping line 674: expected 1 fields, saw 2\\nSkipping line 678: expected 1 fields, saw 2\\nSkipping line 699: expected 1 fields, saw 5\\nSkipping line 706: expected 1 fields, saw 4\\nSkipping line 707: expected 1 fields, saw 2\\nSkipping line 708: expected 1 fields, saw 3\\nSkipping line 711: expected 1 fields, saw 7\\nSkipping line 712: expected 1 fields, saw 7\\nSkipping line 713: expected 1 fields, saw 3\\nSkipping line 732: expected 1 fields, saw 2\\nSkipping line 733: expected 1 fields, saw 2\\nSkipping line 738: expected 1 fields, saw 2\\nSkipping line 745: expected 1 fields, saw 3\\nSkipping line 746: expected 1 fields, saw 3\\nSkipping line 747: expected 1 fields, saw 3\\nSkipping line 755: expected 1 fields, saw 2\\nSkipping line 770: expected 1 fields, saw 2\\nSkipping line 785: expected 1 fields, saw 3\\nSkipping line 786: expected 1 fields, saw 2\\nSkipping line 787: expected 1 fields, saw 6\\nSkipping line 791: expected 1 fields, saw 3\\nSkipping line 793: expected 1 fields, saw 3\\nSkipping line 794: expected 1 fields, saw 2\\nSkipping line 795: expected 1 fields, saw 3\\nSkipping line 797: expected 1 fields, saw 3\\nSkipping line 798: expected 1 fields, saw 2\\nSkipping line 803: expected 1 fields, saw 2\\nSkipping line 805: expected 1 fields, saw 2\\nSkipping line 806: expected 1 fields, saw 2\\nSkipping line 810: expected 1 fields, saw 2\\nSkipping line 812: expected 1 fields, saw 4\\nSkipping line 815: expected 1 fields, saw 2\\nSkipping line 821: expected 1 fields, saw 3\\nSkipping line 824: expected 1 fields, saw 3\\nSkipping line 828: expected 1 fields, saw 2\\nSkipping line 830: expected 1 fields, saw 3\\nSkipping line 832: expected 1 fields, saw 4\\nSkipping line 835: expected 1 fields, saw 2\\nSkipping line 836: expected 1 fields, saw 2\\nSkipping line 838: expected 1 fields, saw 2\\nSkipping line 842: expected 1 fields, saw 4\\nSkipping line 845: expected 1 fields, saw 2\\nSkipping line 847: expected 1 fields, saw 2\\nSkipping line 850: expected 1 fields, saw 5\\nSkipping line 855: expected 1 fields, saw 2\\nSkipping line 857: expected 1 fields, saw 4\\nSkipping line 859: expected 1 fields, saw 2\\nSkipping line 864: expected 1 fields, saw 4\\nSkipping line 865: expected 1 fields, saw 2\\nSkipping line 866: expected 1 fields, saw 3\\nSkipping line 868: expected 1 fields, saw 4\\nSkipping line 869: expected 1 fields, saw 2\\nSkipping line 874: expected 1 fields, saw 6\\nSkipping line 878: expected 1 fields, saw 3\\nSkipping line 891: expected 1 fields, saw 2\\nSkipping line 892: expected 1 fields, saw 2\\nSkipping line 893: expected 1 fields, saw 10\\nSkipping line 894: expected 1 fields, saw 2\\nSkipping line 895: expected 1 fields, saw 6\\nSkipping line 896: expected 1 fields, saw 2\\nSkipping line 898: expected 1 fields, saw 2\\nSkipping line 901: expected 1 fields, saw 2\\nSkipping line 902: expected 1 fields, saw 2\\nSkipping line 904: expected 1 fields, saw 3\\nSkipping line 906: expected 1 fields, saw 3\\nSkipping line 911: expected 1 fields, saw 4\\nSkipping line 915: expected 1 fields, saw 2\\nSkipping line 916: expected 1 fields, saw 6\\nSkipping line 919: expected 1 fields, saw 2\\nSkipping line 923: expected 1 fields, saw 4\\nSkipping line 924: expected 1 fields, saw 2\\nSkipping line 926: expected 1 fields, saw 3\\nSkipping line 930: expected 1 fields, saw 2\\nSkipping line 931: expected 1 fields, saw 4\\nSkipping line 932: expected 1 fields, saw 2\\nSkipping line 934: expected 1 fields, saw 2\\nSkipping line 940: expected 1 fields, saw 2\\nSkipping line 942: expected 1 fields, saw 3\\nSkipping line 943: expected 1 fields, saw 3\\nSkipping line 944: expected 1 fields, saw 4\\nSkipping line 945: expected 1 fields, saw 8\\nSkipping line 946: expected 1 fields, saw 2\\nSkipping line 948: expected 1 fields, saw 2\\nSkipping line 951: expected 1 fields, saw 5\\nSkipping line 959: expected 1 fields, saw 2\\nSkipping line 960: expected 1 fields, saw 3\\nSkipping line 970: expected 1 fields, saw 2\\nSkipping line 971: expected 1 fields, saw 4\\nSkipping line 972: expected 1 fields, saw 3\\nSkipping line 973: expected 1 fields, saw 2\\nSkipping line 975: expected 1 fields, saw 2\\nSkipping line 979: expected 1 fields, saw 2\\nSkipping line 982: expected 1 fields, saw 3\\nSkipping line 985: expected 1 fields, saw 2\\nSkipping line 986: expected 1 fields, saw 3\\nSkipping line 992: expected 1 fields, saw 2\\nSkipping line 993: expected 1 fields, saw 2\\nSkipping line 997: expected 1 fields, saw 3\\nSkipping line 998: expected 1 fields, saw 5\\nSkipping line 999: expected 1 fields, saw 3\\nSkipping line 1000: expected 1 fields, saw 2\\n'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@DarrellMello Dear doctor what should we do if...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@PhantomPower14 what's that presenters problem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@stillgray @KatieDaviscourt @ezralevant She is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@_one901 He has Covid.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Expedia commercial got me in my feels are covi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Content\n",
       "0  @DarrellMello Dear doctor what should we do if...\n",
       "1  @PhantomPower14 what's that presenters problem...\n",
       "2  @stillgray @KatieDaviscourt @ezralevant She is...\n",
       "3                             @_one901 He has Covid.\n",
       "4  Expedia commercial got me in my feels are covi..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "import string\n",
    "\n",
    "#reviews = pd.read_csv('Datafiniti_Hotel_Reviews.csv')\n",
    "df = pd.read_csv('covid.csv', error_bad_lines=False)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56b2650d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@darrellmello dear doctor what should we do if...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@phantompower14 what's that presenters problem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@stillgray @katiedaviscourt @ezralevant she is...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Content\n",
       "0  @darrellmello dear doctor what should we do if...\n",
       "1  @phantompower14 what's that presenters problem...\n",
       "2  @stillgray @katiedaviscourt @ezralevant she is..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Content'] = df['Content'].astype(str).str.lower()\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8529c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>darrellmello dear doctor what should we do if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>phantompower whats that presenters problem  wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stillgray katiedaviscourt ezralevant she is to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>one he has covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expedia commercial got me in my feels are covi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>drkateto the intentional dismissal of the long...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>the one benefit of having covid not having to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>antibloviator timjdillon everyone is going to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>a poem for valentines day \\n\\nroses are red \\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>newstatesman i think its a natural response to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Content\n",
       "0  darrellmello dear doctor what should we do if ...\n",
       "1  phantompower whats that presenters problem  wh...\n",
       "2  stillgray katiedaviscourt ezralevant she is to...\n",
       "3                                   one he has covid\n",
       "4  expedia commercial got me in my feels are covi...\n",
       "5  drkateto the intentional dismissal of the long...\n",
       "6  the one benefit of having covid not having to ...\n",
       "7  antibloviator timjdillon everyone is going to ...\n",
       "8  a poem for valentines day \\n\\nroses are red \\n...\n",
       "9  newstatesman i think its a natural response to..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_punct(text):\n",
    "    text  = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    text = re.sub('[0-9]+', '', text)\n",
    "    return text\n",
    "\n",
    "df['Content'] = df['Content'].apply(lambda x: remove_punct(x))\n",
    "df.head(10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f2e8c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>text_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>darrellmello dear doctor what should we do if ...</td>\n",
       "      <td>[darrellmello, dear, doctor, what, should, we,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>phantompower whats that presenters problem  wh...</td>\n",
       "      <td>[phantompower, whats, that, presenters, proble...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stillgray katiedaviscourt ezralevant she is to...</td>\n",
       "      <td>[stillgray, katiedaviscourt, ezralevant, she, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Content  \\\n",
       "0  darrellmello dear doctor what should we do if ...   \n",
       "1  phantompower whats that presenters problem  wh...   \n",
       "2  stillgray katiedaviscourt ezralevant she is to...   \n",
       "\n",
       "                                          text_token  \n",
       "0  [darrellmello, dear, doctor, what, should, we,...  \n",
       "1  [phantompower, whats, that, presenters, proble...  \n",
       "2  [stillgray, katiedaviscourt, ezralevant, she, ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "regexp = RegexpTokenizer('\\w+')\n",
    "\n",
    "df['text_token']=df['Content'].apply(regexp.tokenize)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88500d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Philip\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e409045",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Make a list of english stopwords\n",
    "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "\n",
    "# Extend the list with your own custom stopwords\n",
    "my_stopwords = ['https']\n",
    "stopwords.extend(my_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5114efc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>text_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>darrellmello dear doctor what should we do if ...</td>\n",
       "      <td>[darrellmello, dear, doctor, post, covid, high...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>phantompower whats that presenters problem  wh...</td>\n",
       "      <td>[phantompower, whats, presenters, problem, wou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stillgray katiedaviscourt ezralevant she is to...</td>\n",
       "      <td>[stillgray, katiedaviscourt, ezralevant, bitte...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Content  \\\n",
       "0  darrellmello dear doctor what should we do if ...   \n",
       "1  phantompower whats that presenters problem  wh...   \n",
       "2  stillgray katiedaviscourt ezralevant she is to...   \n",
       "\n",
       "                                          text_token  \n",
       "0  [darrellmello, dear, doctor, post, covid, high...  \n",
       "1  [phantompower, whats, presenters, problem, wou...  \n",
       "2  [stillgray, katiedaviscourt, ezralevant, bitte...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text_token'] = df['text_token'].apply(lambda x: [item for item in x if item not in stopwords])\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0dbe3e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['text_token'] = df['text_token'].apply(lambda x: ' '.join([item for item in x if len(item)>2]))\n",
    "# df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06b8b2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Philip\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9df45121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>text_token</th>\n",
       "      <th>Tweet_stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>darrellmello dear doctor what should we do if ...</td>\n",
       "      <td>[darrellmello, dear, doctor, post, covid, high...</td>\n",
       "      <td>[darrellmello, dear, doctor, post, covid, high...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>phantompower whats that presenters problem  wh...</td>\n",
       "      <td>[phantompower, whats, presenters, problem, wou...</td>\n",
       "      <td>[phantompow, what, present, problem, would, po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stillgray katiedaviscourt ezralevant she is to...</td>\n",
       "      <td>[stillgray, katiedaviscourt, ezralevant, bitte...</td>\n",
       "      <td>[stillgray, katiedaviscourt, ezralev, bitter, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>one he has covid</td>\n",
       "      <td>[one, covid]</td>\n",
       "      <td>[one, covid]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expedia commercial got me in my feels are covi...</td>\n",
       "      <td>[expedia, commercial, got, feels, covid, kept,...</td>\n",
       "      <td>[expedia, commerci, got, feel, covid, kept, ta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Content  \\\n",
       "0  darrellmello dear doctor what should we do if ...   \n",
       "1  phantompower whats that presenters problem  wh...   \n",
       "2  stillgray katiedaviscourt ezralevant she is to...   \n",
       "3                                   one he has covid   \n",
       "4  expedia commercial got me in my feels are covi...   \n",
       "\n",
       "                                          text_token  \\\n",
       "0  [darrellmello, dear, doctor, post, covid, high...   \n",
       "1  [phantompower, whats, presenters, problem, wou...   \n",
       "2  [stillgray, katiedaviscourt, ezralevant, bitte...   \n",
       "3                                       [one, covid]   \n",
       "4  [expedia, commercial, got, feels, covid, kept,...   \n",
       "\n",
       "                                       Tweet_stemmed  \n",
       "0  [darrellmello, dear, doctor, post, covid, high...  \n",
       "1  [phantompow, what, present, problem, would, po...  \n",
       "2  [stillgray, katiedaviscourt, ezralev, bitter, ...  \n",
       "3                                       [one, covid]  \n",
       "4  [expedia, commerci, got, feel, covid, kept, ta...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps = nltk.PorterStemmer()\n",
    "\n",
    "def stemming(text):\n",
    "    text = [ps.stem(word) for word in text]\n",
    "    return text\n",
    "\n",
    "df['Tweet_stemmed'] = df['text_token'].apply(lambda x: stemming(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6aae08cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>text_token</th>\n",
       "      <th>Tweet_stemmed</th>\n",
       "      <th>Tweet_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>darrellmello dear doctor what should we do if ...</td>\n",
       "      <td>[darrellmello, dear, doctor, post, covid, high...</td>\n",
       "      <td>[darrellmello, dear, doctor, post, covid, high...</td>\n",
       "      <td>[darrellmello, dear, doctor, post, covid, high...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>phantompower whats that presenters problem  wh...</td>\n",
       "      <td>[phantompower, whats, presenters, problem, wou...</td>\n",
       "      <td>[phantompow, what, present, problem, would, po...</td>\n",
       "      <td>[phantompow, what, present, problem, would, po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stillgray katiedaviscourt ezralevant she is to...</td>\n",
       "      <td>[stillgray, katiedaviscourt, ezralevant, bitte...</td>\n",
       "      <td>[stillgray, katiedaviscourt, ezralev, bitter, ...</td>\n",
       "      <td>[stillgray, katiedaviscourt, ezralev, bitter, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>one he has covid</td>\n",
       "      <td>[one, covid]</td>\n",
       "      <td>[one, covid]</td>\n",
       "      <td>[one, covid]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expedia commercial got me in my feels are covi...</td>\n",
       "      <td>[expedia, commercial, got, feels, covid, kept,...</td>\n",
       "      <td>[expedia, commerci, got, feel, covid, kept, ta...</td>\n",
       "      <td>[expedia, commerci, got, feel, covid, kept, ta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Content  \\\n",
       "0  darrellmello dear doctor what should we do if ...   \n",
       "1  phantompower whats that presenters problem  wh...   \n",
       "2  stillgray katiedaviscourt ezralevant she is to...   \n",
       "3                                   one he has covid   \n",
       "4  expedia commercial got me in my feels are covi...   \n",
       "\n",
       "                                          text_token  \\\n",
       "0  [darrellmello, dear, doctor, post, covid, high...   \n",
       "1  [phantompower, whats, presenters, problem, wou...   \n",
       "2  [stillgray, katiedaviscourt, ezralevant, bitte...   \n",
       "3                                       [one, covid]   \n",
       "4  [expedia, commercial, got, feels, covid, kept,...   \n",
       "\n",
       "                                       Tweet_stemmed  \\\n",
       "0  [darrellmello, dear, doctor, post, covid, high...   \n",
       "1  [phantompow, what, present, problem, would, po...   \n",
       "2  [stillgray, katiedaviscourt, ezralev, bitter, ...   \n",
       "3                                       [one, covid]   \n",
       "4  [expedia, commerci, got, feel, covid, kept, ta...   \n",
       "\n",
       "                                    Tweet_lemmatized  \n",
       "0  [darrellmello, dear, doctor, post, covid, high...  \n",
       "1  [phantompow, what, present, problem, would, po...  \n",
       "2  [stillgray, katiedaviscourt, ezralev, bitter, ...  \n",
       "3                                       [one, covid]  \n",
       "4  [expedia, commerci, got, feel, covid, kept, ta...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn = nltk.WordNetLemmatizer()\n",
    "\n",
    "def lemmatizer(text):\n",
    "    text = [wn.lemmatize(word) for word in text]\n",
    "    return text\n",
    "\n",
    "df['Tweet_lemmatized'] = df['Tweet_stemmed'].apply(lambda x: lemmatizer(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "515916b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Philip\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22b09da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\Philip\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('words')\n",
    "words = set(nltk.corpus.words.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15b510f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>text_token</th>\n",
       "      <th>Tweet_stemmed</th>\n",
       "      <th>Tweet_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>darrellmello dear doctor what should we do if ...</td>\n",
       "      <td>[darrellmello, dear, doctor, post, covid, high...</td>\n",
       "      <td>[darrellmello, dear, doctor, post, covid, high...</td>\n",
       "      <td>[dear, doctor, post, covid, high]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>phantompower whats that presenters problem  wh...</td>\n",
       "      <td>[phantompower, whats, presenters, problem, wou...</td>\n",
       "      <td>[phantompow, what, present, problem, would, po...</td>\n",
       "      <td>[what, present, problem, would, want, follow, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stillgray katiedaviscourt ezralevant she is to...</td>\n",
       "      <td>[stillgray, katiedaviscourt, ezralevant, bitte...</td>\n",
       "      <td>[stillgray, katiedaviscourt, ezralev, bitter, ...</td>\n",
       "      <td>[bitter, get, covid]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>one he has covid</td>\n",
       "      <td>[one, covid]</td>\n",
       "      <td>[one, covid]</td>\n",
       "      <td>[one, covid]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expedia commercial got me in my feels are covi...</td>\n",
       "      <td>[expedia, commercial, got, feels, covid, kept,...</td>\n",
       "      <td>[expedia, commerci, got, feel, covid, kept, ta...</td>\n",
       "      <td>[got, feel, covid, kept, take, trip, two, year]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>drkateto the intentional dismissal of the long...</td>\n",
       "      <td>[drkateto, intentional, dismissal, longcovid, ...</td>\n",
       "      <td>[drkateto, intent, dismiss, longcovid, threat,...</td>\n",
       "      <td>[intent, dismiss, threat, health, care, system...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>the one benefit of having covid not having to ...</td>\n",
       "      <td>[one, benefit, covid, early, work, tomorrow, s...</td>\n",
       "      <td>[one, benefit, covid, earli, work, tomorrow, s...</td>\n",
       "      <td>[one, benefit, covid, work, tomorrow]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>antibloviator timjdillon everyone is going to ...</td>\n",
       "      <td>[antibloviator, timjdillon, everyone, going, g...</td>\n",
       "      <td>[antiblovi, timjdillon, everyon, go, get, covi...</td>\n",
       "      <td>[get, covid, matter, way, avoid, alway, wear, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>a poem for valentines day \\n\\nroses are red \\n...</td>\n",
       "      <td>[poem, valentines, day, roses, red, covid, shi...</td>\n",
       "      <td>[poem, valentin, day, rose, red, covid, shit, ...</td>\n",
       "      <td>[poem, day, rose, red, covid, one, love]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>newstatesman i think its a natural response to...</td>\n",
       "      <td>[newstatesman, think, natural, response, traum...</td>\n",
       "      <td>[newstatesman, think, natur, respons, traumat,...</td>\n",
       "      <td>[think, world, covid, unrest]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Content  \\\n",
       "0  darrellmello dear doctor what should we do if ...   \n",
       "1  phantompower whats that presenters problem  wh...   \n",
       "2  stillgray katiedaviscourt ezralevant she is to...   \n",
       "3                                   one he has covid   \n",
       "4  expedia commercial got me in my feels are covi...   \n",
       "5  drkateto the intentional dismissal of the long...   \n",
       "6  the one benefit of having covid not having to ...   \n",
       "7  antibloviator timjdillon everyone is going to ...   \n",
       "8  a poem for valentines day \\n\\nroses are red \\n...   \n",
       "9  newstatesman i think its a natural response to...   \n",
       "\n",
       "                                          text_token  \\\n",
       "0  [darrellmello, dear, doctor, post, covid, high...   \n",
       "1  [phantompower, whats, presenters, problem, wou...   \n",
       "2  [stillgray, katiedaviscourt, ezralevant, bitte...   \n",
       "3                                       [one, covid]   \n",
       "4  [expedia, commercial, got, feels, covid, kept,...   \n",
       "5  [drkateto, intentional, dismissal, longcovid, ...   \n",
       "6  [one, benefit, covid, early, work, tomorrow, s...   \n",
       "7  [antibloviator, timjdillon, everyone, going, g...   \n",
       "8  [poem, valentines, day, roses, red, covid, shi...   \n",
       "9  [newstatesman, think, natural, response, traum...   \n",
       "\n",
       "                                       Tweet_stemmed  \\\n",
       "0  [darrellmello, dear, doctor, post, covid, high...   \n",
       "1  [phantompow, what, present, problem, would, po...   \n",
       "2  [stillgray, katiedaviscourt, ezralev, bitter, ...   \n",
       "3                                       [one, covid]   \n",
       "4  [expedia, commerci, got, feel, covid, kept, ta...   \n",
       "5  [drkateto, intent, dismiss, longcovid, threat,...   \n",
       "6  [one, benefit, covid, earli, work, tomorrow, s...   \n",
       "7  [antiblovi, timjdillon, everyon, go, get, covi...   \n",
       "8  [poem, valentin, day, rose, red, covid, shit, ...   \n",
       "9  [newstatesman, think, natur, respons, traumat,...   \n",
       "\n",
       "                                    Tweet_lemmatized  \n",
       "0                  [dear, doctor, post, covid, high]  \n",
       "1  [what, present, problem, would, want, follow, ...  \n",
       "2                               [bitter, get, covid]  \n",
       "3                                       [one, covid]  \n",
       "4    [got, feel, covid, kept, take, trip, two, year]  \n",
       "5  [intent, dismiss, threat, health, care, system...  \n",
       "6              [one, benefit, covid, work, tomorrow]  \n",
       "7  [get, covid, matter, way, avoid, alway, wear, ...  \n",
       "8           [poem, day, rose, red, covid, one, love]  \n",
       "9                      [think, world, covid, unrest]  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Tweet_lemmatized'] = df['Tweet_lemmatized'].apply(lambda x: ' '.join([item for item in x if len(item)>2]))\n",
    "df['Tweet_lemmatized'] = df['Tweet_lemmatized'].apply(lambda x: [w for w in nltk.wordpunct_tokenize(x) if w.lower() in words or not w.isalpha()])\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d738e7a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[dear, doctor, post, covid, high]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[what, present, problem, would, want, follow, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[bitter, get, covid]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[one, covid]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[got, feel, covid, kept, take, trip, two, year]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Tweet_lemmatized\n",
       "0                  [dear, doctor, post, covid, high]\n",
       "1  [what, present, problem, would, want, follow, ...\n",
       "2                               [bitter, get, covid]\n",
       "3                                       [one, covid]\n",
       "4    [got, feel, covid, kept, take, trip, two, year]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df = pd.DataFrame(df,columns=['Tweet_lemmatized'])\n",
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee69f12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "clean_df.columns = ['Content']\n",
    "clean_df.to_csv('clean_tweet2.csv',encoding='utf-8', index=False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115287bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d7ca128",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2grams test\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
