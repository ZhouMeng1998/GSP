{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Philip\\AppData\\Local\\Temp\\ipykernel_10204\\159182657.py:11: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  reviews = pd.read_csv('covid.csv', error_bad_lines=False)\n",
      "b'Skipping line 6: expected 1 fields, saw 2\\nSkipping line 8: expected 1 fields, saw 2\\nSkipping line 9: expected 1 fields, saw 2\\nSkipping line 17: expected 1 fields, saw 3\\nSkipping line 21: expected 1 fields, saw 2\\nSkipping line 25: expected 1 fields, saw 2\\nSkipping line 27: expected 1 fields, saw 3\\nSkipping line 30: expected 1 fields, saw 2\\nSkipping line 31: expected 1 fields, saw 3\\nSkipping line 32: expected 1 fields, saw 4\\nSkipping line 38: expected 1 fields, saw 4\\nSkipping line 39: expected 1 fields, saw 2\\nSkipping line 56: expected 1 fields, saw 2\\nSkipping line 58: expected 1 fields, saw 2\\nSkipping line 64: expected 1 fields, saw 2\\nSkipping line 66: expected 1 fields, saw 2\\nSkipping line 68: expected 1 fields, saw 2\\nSkipping line 70: expected 1 fields, saw 2\\nSkipping line 72: expected 1 fields, saw 2\\nSkipping line 73: expected 1 fields, saw 2\\nSkipping line 80: expected 1 fields, saw 2\\nSkipping line 81: expected 1 fields, saw 2\\nSkipping line 86: expected 1 fields, saw 2\\nSkipping line 91: expected 1 fields, saw 3\\nSkipping line 92: expected 1 fields, saw 4\\nSkipping line 94: expected 1 fields, saw 3\\nSkipping line 96: expected 1 fields, saw 2\\nSkipping line 99: expected 1 fields, saw 2\\nSkipping line 103: expected 1 fields, saw 3\\nSkipping line 104: expected 1 fields, saw 2\\nSkipping line 105: expected 1 fields, saw 2\\nSkipping line 110: expected 1 fields, saw 2\\nSkipping line 111: expected 1 fields, saw 2\\nSkipping line 112: expected 1 fields, saw 3\\nSkipping line 118: expected 1 fields, saw 2\\nSkipping line 122: expected 1 fields, saw 4\\nSkipping line 124: expected 1 fields, saw 3\\nSkipping line 126: expected 1 fields, saw 2\\nSkipping line 136: expected 1 fields, saw 2\\nSkipping line 139: expected 1 fields, saw 5\\nSkipping line 141: expected 1 fields, saw 2\\nSkipping line 149: expected 1 fields, saw 5\\nSkipping line 165: expected 1 fields, saw 2\\nSkipping line 170: expected 1 fields, saw 4\\nSkipping line 172: expected 1 fields, saw 4\\nSkipping line 173: expected 1 fields, saw 2\\nSkipping line 182: expected 1 fields, saw 3\\nSkipping line 185: expected 1 fields, saw 2\\nSkipping line 192: expected 1 fields, saw 4\\nSkipping line 198: expected 1 fields, saw 4\\nSkipping line 199: expected 1 fields, saw 2\\nSkipping line 201: expected 1 fields, saw 2\\nSkipping line 209: expected 1 fields, saw 3\\nSkipping line 214: expected 1 fields, saw 2\\nSkipping line 219: expected 1 fields, saw 3\\nSkipping line 229: expected 1 fields, saw 2\\nSkipping line 231: expected 1 fields, saw 3\\nSkipping line 233: expected 1 fields, saw 2\\nSkipping line 234: expected 1 fields, saw 5\\nSkipping line 237: expected 1 fields, saw 3\\nSkipping line 238: expected 1 fields, saw 2\\nSkipping line 242: expected 1 fields, saw 4\\nSkipping line 245: expected 1 fields, saw 2\\nSkipping line 246: expected 1 fields, saw 2\\nSkipping line 249: expected 1 fields, saw 2\\nSkipping line 250: expected 1 fields, saw 2\\nSkipping line 253: expected 1 fields, saw 2\\nSkipping line 254: expected 1 fields, saw 3\\nSkipping line 256: expected 1 fields, saw 3\\nSkipping line 258: expected 1 fields, saw 3\\nSkipping line 259: expected 1 fields, saw 3\\nSkipping line 267: expected 1 fields, saw 2\\nSkipping line 268: expected 1 fields, saw 2\\nSkipping line 273: expected 1 fields, saw 4\\nSkipping line 275: expected 1 fields, saw 8\\nSkipping line 279: expected 1 fields, saw 4\\nSkipping line 280: expected 1 fields, saw 2\\nSkipping line 283: expected 1 fields, saw 3\\nSkipping line 286: expected 1 fields, saw 2\\nSkipping line 287: expected 1 fields, saw 3\\nSkipping line 289: expected 1 fields, saw 2\\nSkipping line 291: expected 1 fields, saw 5\\nSkipping line 293: expected 1 fields, saw 2\\nSkipping line 300: expected 1 fields, saw 2\\nSkipping line 302: expected 1 fields, saw 2\\nSkipping line 303: expected 1 fields, saw 6\\nSkipping line 308: expected 1 fields, saw 2\\nSkipping line 324: expected 1 fields, saw 4\\nSkipping line 335: expected 1 fields, saw 6\\nSkipping line 337: expected 1 fields, saw 7\\nSkipping line 339: expected 1 fields, saw 2\\nSkipping line 341: expected 1 fields, saw 2\\nSkipping line 349: expected 1 fields, saw 2\\nSkipping line 362: expected 1 fields, saw 2\\nSkipping line 363: expected 1 fields, saw 3\\nSkipping line 366: expected 1 fields, saw 2\\nSkipping line 368: expected 1 fields, saw 2\\nSkipping line 382: expected 1 fields, saw 2\\nSkipping line 385: expected 1 fields, saw 2\\nSkipping line 388: expected 1 fields, saw 2\\nSkipping line 400: expected 1 fields, saw 2\\nSkipping line 403: expected 1 fields, saw 2\\nSkipping line 404: expected 1 fields, saw 2\\nSkipping line 407: expected 1 fields, saw 4\\nSkipping line 411: expected 1 fields, saw 2\\nSkipping line 412: expected 1 fields, saw 3\\nSkipping line 414: expected 1 fields, saw 2\\nSkipping line 417: expected 1 fields, saw 2\\nSkipping line 418: expected 1 fields, saw 3\\nSkipping line 420: expected 1 fields, saw 2\\nSkipping line 423: expected 1 fields, saw 3\\nSkipping line 429: expected 1 fields, saw 3\\nSkipping line 431: expected 1 fields, saw 3\\nSkipping line 432: expected 1 fields, saw 4\\nSkipping line 439: expected 1 fields, saw 3\\nSkipping line 440: expected 1 fields, saw 4\\nSkipping line 441: expected 1 fields, saw 3\\nSkipping line 442: expected 1 fields, saw 6\\nSkipping line 443: expected 1 fields, saw 2\\nSkipping line 447: expected 1 fields, saw 11\\nSkipping line 452: expected 1 fields, saw 3\\nSkipping line 454: expected 1 fields, saw 6\\nSkipping line 457: expected 1 fields, saw 3\\nSkipping line 458: expected 1 fields, saw 8\\nSkipping line 461: expected 1 fields, saw 2\\nSkipping line 466: expected 1 fields, saw 3\\nSkipping line 470: expected 1 fields, saw 2\\nSkipping line 479: expected 1 fields, saw 3\\nSkipping line 481: expected 1 fields, saw 2\\nSkipping line 485: expected 1 fields, saw 6\\nSkipping line 487: expected 1 fields, saw 3\\nSkipping line 489: expected 1 fields, saw 2\\nSkipping line 490: expected 1 fields, saw 3\\nSkipping line 491: expected 1 fields, saw 3\\nSkipping line 492: expected 1 fields, saw 2\\nSkipping line 498: expected 1 fields, saw 3\\nSkipping line 500: expected 1 fields, saw 3\\nSkipping line 501: expected 1 fields, saw 2\\nSkipping line 502: expected 1 fields, saw 2\\nSkipping line 504: expected 1 fields, saw 2\\nSkipping line 506: expected 1 fields, saw 2\\nSkipping line 509: expected 1 fields, saw 2\\nSkipping line 522: expected 1 fields, saw 3\\nSkipping line 524: expected 1 fields, saw 2\\nSkipping line 525: expected 1 fields, saw 2\\nSkipping line 531: expected 1 fields, saw 4\\nSkipping line 532: expected 1 fields, saw 2\\nSkipping line 546: expected 1 fields, saw 3\\nSkipping line 548: expected 1 fields, saw 3\\nSkipping line 556: expected 1 fields, saw 2\\nSkipping line 558: expected 1 fields, saw 2\\nSkipping line 562: expected 1 fields, saw 3\\nSkipping line 563: expected 1 fields, saw 2\\nSkipping line 566: expected 1 fields, saw 2\\nSkipping line 571: expected 1 fields, saw 3\\nSkipping line 577: expected 1 fields, saw 2\\nSkipping line 580: expected 1 fields, saw 2\\nSkipping line 585: expected 1 fields, saw 3\\nSkipping line 586: expected 1 fields, saw 2\\nSkipping line 588: expected 1 fields, saw 2\\nSkipping line 593: expected 1 fields, saw 4\\nSkipping line 598: expected 1 fields, saw 2\\nSkipping line 600: expected 1 fields, saw 4\\nSkipping line 601: expected 1 fields, saw 2\\nSkipping line 606: expected 1 fields, saw 2\\nSkipping line 611: expected 1 fields, saw 4\\nSkipping line 614: expected 1 fields, saw 2\\nSkipping line 615: expected 1 fields, saw 3\\nSkipping line 616: expected 1 fields, saw 3\\nSkipping line 623: expected 1 fields, saw 2\\nSkipping line 624: expected 1 fields, saw 2\\nSkipping line 625: expected 1 fields, saw 3\\nSkipping line 627: expected 1 fields, saw 3\\nSkipping line 629: expected 1 fields, saw 2\\nSkipping line 631: expected 1 fields, saw 3\\nSkipping line 632: expected 1 fields, saw 3\\nSkipping line 636: expected 1 fields, saw 4\\nSkipping line 637: expected 1 fields, saw 3\\nSkipping line 638: expected 1 fields, saw 3\\nSkipping line 641: expected 1 fields, saw 2\\nSkipping line 646: expected 1 fields, saw 3\\nSkipping line 649: expected 1 fields, saw 2\\nSkipping line 654: expected 1 fields, saw 3\\nSkipping line 660: expected 1 fields, saw 3\\nSkipping line 661: expected 1 fields, saw 2\\nSkipping line 667: expected 1 fields, saw 2\\nSkipping line 669: expected 1 fields, saw 2\\nSkipping line 670: expected 1 fields, saw 2\\nSkipping line 671: expected 1 fields, saw 4\\nSkipping line 674: expected 1 fields, saw 2\\nSkipping line 678: expected 1 fields, saw 2\\nSkipping line 699: expected 1 fields, saw 5\\nSkipping line 706: expected 1 fields, saw 4\\nSkipping line 707: expected 1 fields, saw 2\\nSkipping line 708: expected 1 fields, saw 3\\nSkipping line 711: expected 1 fields, saw 7\\nSkipping line 712: expected 1 fields, saw 7\\nSkipping line 713: expected 1 fields, saw 3\\nSkipping line 732: expected 1 fields, saw 2\\nSkipping line 733: expected 1 fields, saw 2\\nSkipping line 738: expected 1 fields, saw 2\\nSkipping line 745: expected 1 fields, saw 3\\nSkipping line 746: expected 1 fields, saw 3\\nSkipping line 747: expected 1 fields, saw 3\\nSkipping line 755: expected 1 fields, saw 2\\nSkipping line 770: expected 1 fields, saw 2\\nSkipping line 785: expected 1 fields, saw 3\\nSkipping line 786: expected 1 fields, saw 2\\nSkipping line 787: expected 1 fields, saw 6\\nSkipping line 791: expected 1 fields, saw 3\\nSkipping line 793: expected 1 fields, saw 3\\nSkipping line 794: expected 1 fields, saw 2\\nSkipping line 795: expected 1 fields, saw 3\\nSkipping line 797: expected 1 fields, saw 3\\nSkipping line 798: expected 1 fields, saw 2\\nSkipping line 803: expected 1 fields, saw 2\\nSkipping line 805: expected 1 fields, saw 2\\nSkipping line 806: expected 1 fields, saw 2\\nSkipping line 810: expected 1 fields, saw 2\\nSkipping line 812: expected 1 fields, saw 4\\nSkipping line 815: expected 1 fields, saw 2\\nSkipping line 821: expected 1 fields, saw 3\\nSkipping line 824: expected 1 fields, saw 3\\nSkipping line 828: expected 1 fields, saw 2\\nSkipping line 830: expected 1 fields, saw 3\\nSkipping line 832: expected 1 fields, saw 4\\nSkipping line 835: expected 1 fields, saw 2\\nSkipping line 836: expected 1 fields, saw 2\\nSkipping line 838: expected 1 fields, saw 2\\nSkipping line 842: expected 1 fields, saw 4\\nSkipping line 845: expected 1 fields, saw 2\\nSkipping line 847: expected 1 fields, saw 2\\nSkipping line 850: expected 1 fields, saw 5\\nSkipping line 855: expected 1 fields, saw 2\\nSkipping line 857: expected 1 fields, saw 4\\nSkipping line 859: expected 1 fields, saw 2\\nSkipping line 864: expected 1 fields, saw 4\\nSkipping line 865: expected 1 fields, saw 2\\nSkipping line 866: expected 1 fields, saw 3\\nSkipping line 868: expected 1 fields, saw 4\\nSkipping line 869: expected 1 fields, saw 2\\nSkipping line 874: expected 1 fields, saw 6\\nSkipping line 878: expected 1 fields, saw 3\\nSkipping line 891: expected 1 fields, saw 2\\nSkipping line 892: expected 1 fields, saw 2\\nSkipping line 893: expected 1 fields, saw 10\\nSkipping line 894: expected 1 fields, saw 2\\nSkipping line 895: expected 1 fields, saw 6\\nSkipping line 896: expected 1 fields, saw 2\\nSkipping line 898: expected 1 fields, saw 2\\nSkipping line 901: expected 1 fields, saw 2\\nSkipping line 902: expected 1 fields, saw 2\\nSkipping line 904: expected 1 fields, saw 3\\nSkipping line 906: expected 1 fields, saw 3\\nSkipping line 911: expected 1 fields, saw 4\\nSkipping line 915: expected 1 fields, saw 2\\nSkipping line 916: expected 1 fields, saw 6\\nSkipping line 919: expected 1 fields, saw 2\\nSkipping line 923: expected 1 fields, saw 4\\nSkipping line 924: expected 1 fields, saw 2\\nSkipping line 926: expected 1 fields, saw 3\\nSkipping line 930: expected 1 fields, saw 2\\nSkipping line 931: expected 1 fields, saw 4\\nSkipping line 932: expected 1 fields, saw 2\\nSkipping line 934: expected 1 fields, saw 2\\nSkipping line 940: expected 1 fields, saw 2\\nSkipping line 942: expected 1 fields, saw 3\\nSkipping line 943: expected 1 fields, saw 3\\nSkipping line 944: expected 1 fields, saw 4\\nSkipping line 945: expected 1 fields, saw 8\\nSkipping line 946: expected 1 fields, saw 2\\nSkipping line 948: expected 1 fields, saw 2\\nSkipping line 951: expected 1 fields, saw 5\\nSkipping line 959: expected 1 fields, saw 2\\nSkipping line 960: expected 1 fields, saw 3\\nSkipping line 970: expected 1 fields, saw 2\\nSkipping line 971: expected 1 fields, saw 4\\nSkipping line 972: expected 1 fields, saw 3\\nSkipping line 973: expected 1 fields, saw 2\\nSkipping line 975: expected 1 fields, saw 2\\nSkipping line 979: expected 1 fields, saw 2\\nSkipping line 982: expected 1 fields, saw 3\\nSkipping line 985: expected 1 fields, saw 2\\nSkipping line 986: expected 1 fields, saw 3\\nSkipping line 992: expected 1 fields, saw 2\\nSkipping line 993: expected 1 fields, saw 2\\nSkipping line 997: expected 1 fields, saw 3\\nSkipping line 998: expected 1 fields, saw 5\\nSkipping line 999: expected 1 fields, saw 3\\nSkipping line 1000: expected 1 fields, saw 2\\n'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@DarrellMello Dear doctor what should we do if...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@PhantomPower14 what's that presenters problem...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Content\n",
       "0  @DarrellMello Dear doctor what should we do if...\n",
       "1  @PhantomPower14 what's that presenters problem..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "import string\n",
    "\n",
    "# reviews = pd.read_csv('Datafiniti_Hotel_Reviews.csv')\n",
    "reviews = pd.read_csv('covid.csv', error_bad_lines=False)\n",
    "reviews.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Philip\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#comments = reviews['reviews.text']\n",
    "comments = reviews['Content']\n",
    "\n",
    "comments.head(2)\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    @DarrellMello Dear doctor what should we do if...\n",
       "1    @PhantomPower14 what's that presenters problem...\n",
       "2    @stillgray @KatieDaviscourt @ezralevant She is...\n",
       "3                               @_one901 He has Covid.\n",
       "4    Expedia commercial got me in my feels are covi...\n",
       "Name: Content, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#function to remove non-ascii characters\n",
    "def _removeNonAscii(s): return \"\".join(i for i in s if ord(i)<128)\n",
    "comments = comments.astype('str')\n",
    "#remove non-ascii characters\n",
    "comments = comments.map(lambda x: _removeNonAscii(x))\n",
    "#get stop words of all languages\n",
    "STOPWORDS_DICT = {lang: set(nltk.corpus.stopwords.words(lang)) for lang in nltk.corpus.stopwords.fileids()}\n",
    "#function to detect language based on # of stop words for particular language\n",
    "def get_language(text):\n",
    "    words = set(nltk.wordpunct_tokenize(text.lower()))\n",
    "    lang = max(((lang, len(words & stopwords)) for lang, stopwords in STOPWORDS_DICT.items()), key = lambda x: x[1])[0]\n",
    "    if lang == 'english':\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "#filter for only english comments\n",
    "eng_comments=comments[comments.apply(get_language)]\n",
    "eng_comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [ , darrellmello, dear, doctor, what, should, ...\n",
       "1    [ , phantompower14, what, s, that, presenter, ...\n",
       "Name: Content, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop duplicates\n",
    "eng_comments.drop_duplicates(inplace=True)\n",
    "#load spacy\n",
    "# nlp = spacy.load('en')\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "# nlp = en_core_web_sm.load()\n",
    "\n",
    "#function to clean and lemmatize comments\n",
    "def clean_comments(text):\n",
    "    #remove punctuations\n",
    "    regex = re.compile('[' + re.escape(string.punctuation) + '\\\\r\\\\t\\\\n]')\n",
    "    nopunct = regex.sub(\" \", str(text))\n",
    "    #use spacy to lemmatize comments\n",
    "    doc = nlp(nopunct, disable=['parser','ner'])\n",
    "    lemma = [token.lemma_ for token in doc]\n",
    "    return lemma\n",
    "#apply function to clean and lemmatize comments\n",
    "lemmatized = eng_comments.map(clean_comments)\n",
    "#make sure to lowercase everything\n",
    "lemmatized = lemmatized.map(lambda x: [word.lower() for word in x])\n",
    "lemmatized.head(2)\n",
    "\n",
    "\n",
    "# lemmatized = lemmatized.apply(lambda x: ' '.join([item for item in x if len(item)>2]))\n",
    "# lemmatized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlist_comments = [item for items in lemmatized for item in items]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigram</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(covid,  )</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>( , i)</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(i, m)</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(do, not)</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(have, covid)</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          bigram  freq\n",
       "0     (covid,  )   127\n",
       "1         ( , i)   106\n",
       "2         (i, m)    79\n",
       "3      (do, not)    64\n",
       "4  (have, covid)    62"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams = nltk.collocations.BigramAssocMeasures()\n",
    "trigrams = nltk.collocations.TrigramAssocMeasures()\n",
    "bigramFinder = nltk.collocations.BigramCollocationFinder.from_words(unlist_comments)\n",
    "trigramFinder = nltk.collocations.TrigramCollocationFinder.from_words(unlist_comments)\n",
    "\n",
    "bigram_freq = bigramFinder.ngram_fd.items()\n",
    "bigramFreqTable = pd.DataFrame(list(bigram_freq), columns=['bigram','freq']).sort_values(by='freq', ascending=False)\n",
    "bigramFreqTable.head().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Philip\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bigram</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>(get, covid)</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>(covid,   )</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>(covid, test)</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1583</th>\n",
       "      <td>(covid, vaccine)</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>(super, bowl)</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2870</th>\n",
       "      <td>(catch, covid)</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>(think, covid)</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2670</th>\n",
       "      <td>(covid, death)</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>(  , covid)</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3464</th>\n",
       "      <td>(last, year)</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                bigram  freq\n",
       "49        (get, covid)    42\n",
       "50         (covid,   )    29\n",
       "372      (covid, test)    15\n",
       "1583  (covid, vaccine)    11\n",
       "589      (super, bowl)    10\n",
       "2870    (catch, covid)     9\n",
       "531     (think, covid)     7\n",
       "2670    (covid, death)     7\n",
       "336        (  , covid)     7\n",
       "3464      (last, year)     6"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "bigramFreqTable[:10]\n",
    "#get english stopwords\n",
    "en_stopwords = set(stopwords.words('english'))\n",
    "#function to filter for ADJ/NN bigrams\n",
    "def rightTypes(ngram):\n",
    "    if '-pron-' in ngram or '' in ngram or ' 'in ngram or 't' in ngram:\n",
    "        return False\n",
    "    for word in ngram:\n",
    "        if word in en_stopwords:\n",
    "            return False\n",
    "    acceptable_types = ('JJ', 'JJR', 'JJS', 'NN', 'NNS', 'NNP', 'NNPS')\n",
    "    second_type = ('NN', 'NNS', 'NNP', 'NNPS')\n",
    "    tags = nltk.pos_tag(ngram)\n",
    "    if tags[0][1] in acceptable_types and tags[1][1] in second_type:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "#filter bigrams\n",
    "filtered_bi = bigramFreqTable[bigramFreqTable.bigram.map(lambda x: rightTypes(x))]\n",
    "filtered_bi[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trigram</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>( , amp,  )</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(i, do, not)</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>( , i, m)</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(have, covid,  )</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(covid,  , i)</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            trigram  freq\n",
       "0       ( , amp,  )    30\n",
       "1      (i, do, not)    22\n",
       "2         ( , i, m)    22\n",
       "3  (have, covid,  )    20\n",
       "4     (covid,  , i)    14"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram_freq = trigramFinder.ngram_fd.items()\n",
    "trigramFreqTable = pd.DataFrame(list(trigram_freq), columns=['trigram','freq']).sort_values(by='freq', ascending=False)\n",
    "trigramFreqTable.head().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trigram</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>848</th>\n",
       "      <td>( , amp,  )</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>937</th>\n",
       "      <td>(i, do, not)</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>( , i, m)</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>(have, covid,  )</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>(covid,  , i)</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>(  , i, m)</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>(positive, for, covid)</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>(wear, a, mask)</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>(i, m, not)</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2699</th>\n",
       "      <td>(i, don, t)</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     trigram  freq\n",
       "848              ( , amp,  )    30\n",
       "937             (i, do, not)    22\n",
       "656                ( , i, m)    22\n",
       "141         (have, covid,  )    20\n",
       "935            (covid,  , i)    14\n",
       "215               (  , i, m)    13\n",
       "272   (positive, for, covid)    12\n",
       "838          (wear, a, mask)    12\n",
       "925              (i, m, not)    12\n",
       "2699             (i, don, t)    12"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigramFreqTable[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trigram</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>(covid, 19, vaccine)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4019</th>\n",
       "      <td>(covid, 19, case)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4251</th>\n",
       "      <td>(last, 2, year)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13499</th>\n",
       "      <td>(covid, 19, vaccination)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6615</th>\n",
       "      <td>(covid, yeji, test)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9183</th>\n",
       "      <td>(yuna, test, negative)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7736</th>\n",
       "      <td>(public, health, measure)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15200</th>\n",
       "      <td>(covid, narrative, falls)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2843</th>\n",
       "      <td>(post, viral, syndrome)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11264</th>\n",
       "      <td>(covid, last, year)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         trigram  freq\n",
       "1793        (covid, 19, vaccine)     4\n",
       "4019           (covid, 19, case)     3\n",
       "4251             (last, 2, year)     3\n",
       "13499   (covid, 19, vaccination)     2\n",
       "6615         (covid, yeji, test)     2\n",
       "9183      (yuna, test, negative)     2\n",
       "7736   (public, health, measure)     2\n",
       "15200  (covid, narrative, falls)     2\n",
       "2843     (post, viral, syndrome)     2\n",
       "11264        (covid, last, year)     2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rightTypesTri(ngram):\n",
    "    if '-pron-' in ngram or '' in ngram or ' 'in ngram or '  ' in ngram or 't' in ngram:\n",
    "        return False\n",
    "    for word in ngram:\n",
    "        if word in en_stopwords:\n",
    "            return False\n",
    "    first_type = ('JJ', 'JJR', 'JJS', 'NN', 'NNS', 'NNP', 'NNPS')\n",
    "    third_type = ('JJ', 'JJR', 'JJS', 'NN', 'NNS', 'NNP', 'NNPS')\n",
    "    tags = nltk.pos_tag(ngram)\n",
    "    if tags[0][1] in first_type and tags[2][1] in third_type:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "filtered_tri = trigramFreqTable[trigramFreqTable.trigram.map(lambda x: rightTypesTri(x))]\n",
    "filtered_tri[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
