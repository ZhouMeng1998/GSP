{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d15dffee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Philip\\AppData\\Local\\Temp\\ipykernel_5772\\3721099668.py:11: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  df = pd.read_csv('covid_tweets_600.csv', error_bad_lines=False)\n",
      "b'Skipping line 5: expected 1 fields, saw 2\\nSkipping line 9: expected 1 fields, saw 3\\nSkipping line 11: expected 1 fields, saw 3\\nSkipping line 20: expected 1 fields, saw 3\\nSkipping line 22: expected 1 fields, saw 2\\nSkipping line 25: expected 1 fields, saw 2\\nSkipping line 27: expected 1 fields, saw 3\\nSkipping line 28: expected 1 fields, saw 2\\nSkipping line 35: expected 1 fields, saw 2\\nSkipping line 37: expected 1 fields, saw 6\\nSkipping line 38: expected 1 fields, saw 3\\nSkipping line 43: expected 1 fields, saw 3\\nSkipping line 54: expected 1 fields, saw 3\\nSkipping line 58: expected 1 fields, saw 3\\nSkipping line 59: expected 1 fields, saw 2\\nSkipping line 60: expected 1 fields, saw 4\\nSkipping line 67: expected 1 fields, saw 2\\nSkipping line 69: expected 1 fields, saw 2\\nSkipping line 70: expected 1 fields, saw 3\\nSkipping line 74: expected 1 fields, saw 2\\nSkipping line 76: expected 1 fields, saw 3\\nSkipping line 77: expected 1 fields, saw 2\\nSkipping line 84: expected 1 fields, saw 2\\nSkipping line 86: expected 1 fields, saw 2\\nSkipping line 88: expected 1 fields, saw 2\\nSkipping line 90: expected 1 fields, saw 3\\nSkipping line 92: expected 1 fields, saw 5\\nSkipping line 94: expected 1 fields, saw 2\\nSkipping line 96: expected 1 fields, saw 3\\nSkipping line 105: expected 1 fields, saw 2\\nSkipping line 109: expected 1 fields, saw 2\\nSkipping line 110: expected 1 fields, saw 2\\nSkipping line 113: expected 1 fields, saw 2\\nSkipping line 127: expected 1 fields, saw 2\\nSkipping line 135: expected 1 fields, saw 2\\nSkipping line 137: expected 1 fields, saw 3\\nSkipping line 139: expected 1 fields, saw 2\\nSkipping line 143: expected 1 fields, saw 2\\nSkipping line 145: expected 1 fields, saw 2\\nSkipping line 147: expected 1 fields, saw 2\\nSkipping line 149: expected 1 fields, saw 3\\nSkipping line 153: expected 1 fields, saw 3\\nSkipping line 154: expected 1 fields, saw 2\\nSkipping line 156: expected 1 fields, saw 3\\nSkipping line 160: expected 1 fields, saw 2\\nSkipping line 162: expected 1 fields, saw 2\\nSkipping line 164: expected 1 fields, saw 2\\nSkipping line 166: expected 1 fields, saw 3\\nSkipping line 167: expected 1 fields, saw 2\\nSkipping line 169: expected 1 fields, saw 2\\nSkipping line 173: expected 1 fields, saw 2\\nSkipping line 175: expected 1 fields, saw 3\\nSkipping line 185: expected 1 fields, saw 2\\nSkipping line 189: expected 1 fields, saw 3\\nSkipping line 194: expected 1 fields, saw 5\\nSkipping line 208: expected 1 fields, saw 3\\nSkipping line 212: expected 1 fields, saw 2\\nSkipping line 214: expected 1 fields, saw 4\\nSkipping line 221: expected 1 fields, saw 2\\nSkipping line 225: expected 1 fields, saw 5\\nSkipping line 228: expected 1 fields, saw 2\\nSkipping line 230: expected 1 fields, saw 5\\nSkipping line 238: expected 1 fields, saw 2\\nSkipping line 243: expected 1 fields, saw 2\\nSkipping line 246: expected 1 fields, saw 2\\nSkipping line 248: expected 1 fields, saw 3\\nSkipping line 260: expected 1 fields, saw 2\\nSkipping line 261: expected 1 fields, saw 2\\nSkipping line 264: expected 1 fields, saw 2\\nSkipping line 266: expected 1 fields, saw 3\\nSkipping line 268: expected 1 fields, saw 2\\nSkipping line 288: expected 1 fields, saw 2\\nSkipping line 295: expected 1 fields, saw 2\\nSkipping line 296: expected 1 fields, saw 3\\nSkipping line 305: expected 1 fields, saw 3\\nSkipping line 318: expected 1 fields, saw 2\\nSkipping line 321: expected 1 fields, saw 3\\nSkipping line 322: expected 1 fields, saw 8\\nSkipping line 324: expected 1 fields, saw 2\\nSkipping line 325: expected 1 fields, saw 3\\nSkipping line 331: expected 1 fields, saw 3\\nSkipping line 333: expected 1 fields, saw 2\\nSkipping line 334: expected 1 fields, saw 3\\nSkipping line 336: expected 1 fields, saw 2\\nSkipping line 340: expected 1 fields, saw 3\\nSkipping line 341: expected 1 fields, saw 5\\nSkipping line 344: expected 1 fields, saw 2\\nSkipping line 352: expected 1 fields, saw 3\\nSkipping line 354: expected 1 fields, saw 3\\nSkipping line 358: expected 1 fields, saw 2\\nSkipping line 360: expected 1 fields, saw 2\\nSkipping line 361: expected 1 fields, saw 2\\nSkipping line 363: expected 1 fields, saw 2\\nSkipping line 369: expected 1 fields, saw 2\\nSkipping line 371: expected 1 fields, saw 3\\nSkipping line 373: expected 1 fields, saw 2\\nSkipping line 381: expected 1 fields, saw 2\\nSkipping line 382: expected 1 fields, saw 4\\nSkipping line 385: expected 1 fields, saw 2\\nSkipping line 387: expected 1 fields, saw 5\\nSkipping line 392: expected 1 fields, saw 4\\nSkipping line 396: expected 1 fields, saw 2\\nSkipping line 400: expected 1 fields, saw 2\\nSkipping line 403: expected 1 fields, saw 4\\nSkipping line 407: expected 1 fields, saw 5\\nSkipping line 409: expected 1 fields, saw 4\\nSkipping line 413: expected 1 fields, saw 4\\nSkipping line 414: expected 1 fields, saw 2\\nSkipping line 418: expected 1 fields, saw 6\\nSkipping line 419: expected 1 fields, saw 3\\nSkipping line 424: expected 1 fields, saw 2\\nSkipping line 431: expected 1 fields, saw 4\\nSkipping line 432: expected 1 fields, saw 3\\nSkipping line 433: expected 1 fields, saw 3\\nSkipping line 434: expected 1 fields, saw 3\\nSkipping line 437: expected 1 fields, saw 3\\nSkipping line 438: expected 1 fields, saw 2\\nSkipping line 448: expected 1 fields, saw 2\\nSkipping line 451: expected 1 fields, saw 2\\nSkipping line 452: expected 1 fields, saw 6\\nSkipping line 458: expected 1 fields, saw 2\\nSkipping line 470: expected 1 fields, saw 5\\nSkipping line 475: expected 1 fields, saw 3\\nSkipping line 476: expected 1 fields, saw 2\\nSkipping line 479: expected 1 fields, saw 2\\nSkipping line 480: expected 1 fields, saw 5\\nSkipping line 482: expected 1 fields, saw 2\\nSkipping line 483: expected 1 fields, saw 3\\nSkipping line 489: expected 1 fields, saw 2\\nSkipping line 492: expected 1 fields, saw 3\\nSkipping line 493: expected 1 fields, saw 5\\nSkipping line 500: expected 1 fields, saw 4\\nSkipping line 504: expected 1 fields, saw 2\\nSkipping line 508: expected 1 fields, saw 2\\nSkipping line 510: expected 1 fields, saw 2\\nSkipping line 511: expected 1 fields, saw 2\\nSkipping line 516: expected 1 fields, saw 2\\nSkipping line 525: expected 1 fields, saw 2\\nSkipping line 533: expected 1 fields, saw 2\\nSkipping line 538: expected 1 fields, saw 3\\nSkipping line 541: expected 1 fields, saw 2\\nSkipping line 542: expected 1 fields, saw 2\\nSkipping line 543: expected 1 fields, saw 2\\nSkipping line 550: expected 1 fields, saw 4\\nSkipping line 553: expected 1 fields, saw 4\\nSkipping line 554: expected 1 fields, saw 2\\nSkipping line 558: expected 1 fields, saw 2\\nSkipping line 562: expected 1 fields, saw 5\\nSkipping line 564: expected 1 fields, saw 8\\nSkipping line 565: expected 1 fields, saw 2\\nSkipping line 568: expected 1 fields, saw 2\\nSkipping line 570: expected 1 fields, saw 3\\nSkipping line 572: expected 1 fields, saw 2\\nSkipping line 575: expected 1 fields, saw 2\\nSkipping line 577: expected 1 fields, saw 2\\nSkipping line 585: expected 1 fields, saw 3\\nSkipping line 586: expected 1 fields, saw 2\\nSkipping line 587: expected 1 fields, saw 5\\nSkipping line 591: expected 1 fields, saw 2\\nSkipping line 592: expected 1 fields, saw 4\\nSkipping line 595: expected 1 fields, saw 3\\nSkipping line 599: expected 1 fields, saw 4\\n'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Love getting COVID exposed by my idiot coworke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hepatitis C Virus Reactivation Following COVID...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>memorial day weekend was a dream\\n1. face the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When you test positive for Covid but find out ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4/15 ppl in my office (though i think it might...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Content\n",
       "0  Love getting COVID exposed by my idiot coworke...\n",
       "1  Hepatitis C Virus Reactivation Following COVID...\n",
       "2  memorial day weekend was a dream\\n1. face the ...\n",
       "3  When you test positive for Covid but find out ...\n",
       "4  4/15 ppl in my office (though i think it might..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "import string\n",
    "\n",
    "#reviews = pd.read_csv('Datafiniti_Hotel_Reviews.csv')\n",
    "df = pd.read_csv('covid_tweets_600.csv', error_bad_lines=False)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56b2650d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>love getting covid exposed by my idiot coworke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hepatitis c virus reactivation following covid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>memorial day weekend was a dream\\n1. face the ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Content\n",
       "0  love getting covid exposed by my idiot coworke...\n",
       "1  hepatitis c virus reactivation following covid...\n",
       "2  memorial day weekend was a dream\\n1. face the ..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Content'] = df['Content'].astype(str).str.lower()\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8529c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>love getting covid exposed by my idiot coworke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hepatitis c virus reactivation following covid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>memorial day weekend was a dream\\n face the fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>when you test positive for covid but find out ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ppl in my office though i think it might be  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>feels fitting to miss out on my last week of f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>just got a delivery of one of my favorite perf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>one thing covid fucked up was me missing her b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>there are  letters in the new email handle for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>nice lil paid covid vacation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Content\n",
       "0  love getting covid exposed by my idiot coworke...\n",
       "1  hepatitis c virus reactivation following covid...\n",
       "2  memorial day weekend was a dream\\n face the fa...\n",
       "3  when you test positive for covid but find out ...\n",
       "4   ppl in my office though i think it might be  ...\n",
       "5  feels fitting to miss out on my last week of f...\n",
       "6  just got a delivery of one of my favorite perf...\n",
       "7  one thing covid fucked up was me missing her b...\n",
       "8  there are  letters in the new email handle for...\n",
       "9                       nice lil paid covid vacation"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_punct(text):\n",
    "    text  = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    text = re.sub('[0-9]+', '', text)\n",
    "    return text\n",
    "\n",
    "df['Content'] = df['Content'].apply(lambda x: remove_punct(x))\n",
    "df.head(10)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f2e8c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>text_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>love getting covid exposed by my idiot coworke...</td>\n",
       "      <td>[love, getting, covid, exposed, by, my, idiot,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hepatitis c virus reactivation following covid...</td>\n",
       "      <td>[hepatitis, c, virus, reactivation, following,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>memorial day weekend was a dream\\n face the fa...</td>\n",
       "      <td>[memorial, day, weekend, was, a, dream, face, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Content  \\\n",
       "0  love getting covid exposed by my idiot coworke...   \n",
       "1  hepatitis c virus reactivation following covid...   \n",
       "2  memorial day weekend was a dream\\n face the fa...   \n",
       "\n",
       "                                          text_token  \n",
       "0  [love, getting, covid, exposed, by, my, idiot,...  \n",
       "1  [hepatitis, c, virus, reactivation, following,...  \n",
       "2  [memorial, day, weekend, was, a, dream, face, ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "regexp = RegexpTokenizer('\\w+')\n",
    "\n",
    "df['text_token']=df['Content'].apply(regexp.tokenize)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88500d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Philip\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e409045",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Make a list of english stopwords\n",
    "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "\n",
    "# Extend the list with your own custom stopwords\n",
    "my_stopwords = ['https']\n",
    "stopwords.extend(my_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5114efc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>text_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>love getting covid exposed by my idiot coworke...</td>\n",
       "      <td>[love, getting, covid, exposed, idiot, coworke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hepatitis c virus reactivation following covid...</td>\n",
       "      <td>[hepatitis, c, virus, reactivation, following,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>memorial day weekend was a dream\\n face the fa...</td>\n",
       "      <td>[memorial, day, weekend, dream, face, facts, d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Content  \\\n",
       "0  love getting covid exposed by my idiot coworke...   \n",
       "1  hepatitis c virus reactivation following covid...   \n",
       "2  memorial day weekend was a dream\\n face the fa...   \n",
       "\n",
       "                                          text_token  \n",
       "0  [love, getting, covid, exposed, idiot, coworke...  \n",
       "1  [hepatitis, c, virus, reactivation, following,...  \n",
       "2  [memorial, day, weekend, dream, face, facts, d...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text_token'] = df['text_token'].apply(lambda x: [item for item in x if item not in stopwords])\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0dbe3e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['text_token'] = df['text_token'].apply(lambda x: ' '.join([item for item in x if len(item)>2]))\n",
    "# df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06b8b2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Philip\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9df45121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>text_token</th>\n",
       "      <th>Tweet_stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>love getting covid exposed by my idiot coworke...</td>\n",
       "      <td>[love, getting, covid, exposed, idiot, coworke...</td>\n",
       "      <td>[love, get, covid, expos, idiot, cowork, feel,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hepatitis c virus reactivation following covid...</td>\n",
       "      <td>[hepatitis, c, virus, reactivation, following,...</td>\n",
       "      <td>[hepat, c, viru, reactiv, follow, covid, vacci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>memorial day weekend was a dream\\n face the fa...</td>\n",
       "      <td>[memorial, day, weekend, dream, face, facts, d...</td>\n",
       "      <td>[memori, day, weekend, dream, face, fact, dont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>when you test positive for covid but find out ...</td>\n",
       "      <td>[test, positive, covid, find, offer, accepted,...</td>\n",
       "      <td>[test, posit, covid, find, offer, accept, drea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ppl in my office though i think it might be  ...</td>\n",
       "      <td>[ppl, office, though, think, might, bc, one, c...</td>\n",
       "      <td>[ppl, offic, though, think, might, bc, one, cw...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Content  \\\n",
       "0  love getting covid exposed by my idiot coworke...   \n",
       "1  hepatitis c virus reactivation following covid...   \n",
       "2  memorial day weekend was a dream\\n face the fa...   \n",
       "3  when you test positive for covid but find out ...   \n",
       "4   ppl in my office though i think it might be  ...   \n",
       "\n",
       "                                          text_token  \\\n",
       "0  [love, getting, covid, exposed, idiot, coworke...   \n",
       "1  [hepatitis, c, virus, reactivation, following,...   \n",
       "2  [memorial, day, weekend, dream, face, facts, d...   \n",
       "3  [test, positive, covid, find, offer, accepted,...   \n",
       "4  [ppl, office, though, think, might, bc, one, c...   \n",
       "\n",
       "                                       Tweet_stemmed  \n",
       "0  [love, get, covid, expos, idiot, cowork, feel,...  \n",
       "1  [hepat, c, viru, reactiv, follow, covid, vacci...  \n",
       "2  [memori, day, weekend, dream, face, fact, dont...  \n",
       "3  [test, posit, covid, find, offer, accept, drea...  \n",
       "4  [ppl, offic, though, think, might, bc, one, cw...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps = nltk.PorterStemmer()\n",
    "\n",
    "def stemming(text):\n",
    "    text = [ps.stem(word) for word in text]\n",
    "    return text\n",
    "\n",
    "df['Tweet_stemmed'] = df['text_token'].apply(lambda x: stemming(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6aae08cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>text_token</th>\n",
       "      <th>Tweet_stemmed</th>\n",
       "      <th>Tweet_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>love getting covid exposed by my idiot coworke...</td>\n",
       "      <td>[love, getting, covid, exposed, idiot, coworke...</td>\n",
       "      <td>[love, get, covid, expos, idiot, cowork, feel,...</td>\n",
       "      <td>[love, get, covid, expo, idiot, cowork, feel, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hepatitis c virus reactivation following covid...</td>\n",
       "      <td>[hepatitis, c, virus, reactivation, following,...</td>\n",
       "      <td>[hepat, c, viru, reactiv, follow, covid, vacci...</td>\n",
       "      <td>[hepat, c, viru, reactiv, follow, covid, vacci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>memorial day weekend was a dream\\n face the fa...</td>\n",
       "      <td>[memorial, day, weekend, dream, face, facts, d...</td>\n",
       "      <td>[memori, day, weekend, dream, face, fact, dont...</td>\n",
       "      <td>[memori, day, weekend, dream, face, fact, dont...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>when you test positive for covid but find out ...</td>\n",
       "      <td>[test, positive, covid, find, offer, accepted,...</td>\n",
       "      <td>[test, posit, covid, find, offer, accept, drea...</td>\n",
       "      <td>[test, posit, covid, find, offer, accept, drea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ppl in my office though i think it might be  ...</td>\n",
       "      <td>[ppl, office, though, think, might, bc, one, c...</td>\n",
       "      <td>[ppl, offic, though, think, might, bc, one, cw...</td>\n",
       "      <td>[ppl, offic, though, think, might, bc, one, cw...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Content  \\\n",
       "0  love getting covid exposed by my idiot coworke...   \n",
       "1  hepatitis c virus reactivation following covid...   \n",
       "2  memorial day weekend was a dream\\n face the fa...   \n",
       "3  when you test positive for covid but find out ...   \n",
       "4   ppl in my office though i think it might be  ...   \n",
       "\n",
       "                                          text_token  \\\n",
       "0  [love, getting, covid, exposed, idiot, coworke...   \n",
       "1  [hepatitis, c, virus, reactivation, following,...   \n",
       "2  [memorial, day, weekend, dream, face, facts, d...   \n",
       "3  [test, positive, covid, find, offer, accepted,...   \n",
       "4  [ppl, office, though, think, might, bc, one, c...   \n",
       "\n",
       "                                       Tweet_stemmed  \\\n",
       "0  [love, get, covid, expos, idiot, cowork, feel,...   \n",
       "1  [hepat, c, viru, reactiv, follow, covid, vacci...   \n",
       "2  [memori, day, weekend, dream, face, fact, dont...   \n",
       "3  [test, posit, covid, find, offer, accept, drea...   \n",
       "4  [ppl, offic, though, think, might, bc, one, cw...   \n",
       "\n",
       "                                    Tweet_lemmatized  \n",
       "0  [love, get, covid, expo, idiot, cowork, feel, ...  \n",
       "1  [hepat, c, viru, reactiv, follow, covid, vacci...  \n",
       "2  [memori, day, weekend, dream, face, fact, dont...  \n",
       "3  [test, posit, covid, find, offer, accept, drea...  \n",
       "4  [ppl, offic, though, think, might, bc, one, cw...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn = nltk.WordNetLemmatizer()\n",
    "\n",
    "def lemmatizer(text):\n",
    "    text = [wn.lemmatize(word) for word in text]\n",
    "    return text\n",
    "\n",
    "df['Tweet_lemmatized'] = df['Tweet_stemmed'].apply(lambda x: lemmatizer(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "515916b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Philip\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22b09da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\Philip\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('words')\n",
    "words = set(nltk.corpus.words.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15b510f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "      <th>text_token</th>\n",
       "      <th>Tweet_stemmed</th>\n",
       "      <th>Tweet_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>love getting covid exposed by my idiot coworke...</td>\n",
       "      <td>[love, getting, covid, exposed, idiot, coworke...</td>\n",
       "      <td>[love, get, covid, expos, idiot, cowork, feel,...</td>\n",
       "      <td>[love, get, covid, idiot, feel, sick, yesterda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hepatitis c virus reactivation following covid...</td>\n",
       "      <td>[hepatitis, c, virus, reactivation, following,...</td>\n",
       "      <td>[hepat, c, viru, reactiv, follow, covid, vacci...</td>\n",
       "      <td>[follow, covid, infect, covid, manifest, loss,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>memorial day weekend was a dream\\n face the fa...</td>\n",
       "      <td>[memorial, day, weekend, dream, face, facts, d...</td>\n",
       "      <td>[memori, day, weekend, dream, face, fact, dont...</td>\n",
       "      <td>[day, weekend, dream, face, fact, dont, know, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>when you test positive for covid but find out ...</td>\n",
       "      <td>[test, positive, covid, find, offer, accepted,...</td>\n",
       "      <td>[test, posit, covid, find, offer, accept, drea...</td>\n",
       "      <td>[test, posit, covid, find, offer, accept, drea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ppl in my office though i think it might be  ...</td>\n",
       "      <td>[ppl, office, though, think, might, bc, one, c...</td>\n",
       "      <td>[ppl, offic, though, think, might, bc, one, cw...</td>\n",
       "      <td>[though, think, might, one, covid, last, week]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>feels fitting to miss out on my last week of f...</td>\n",
       "      <td>[feels, fitting, miss, last, week, field, work...</td>\n",
       "      <td>[feel, fit, miss, last, week, field, work, job...</td>\n",
       "      <td>[feel, fit, miss, last, week, field, work, job...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>just got a delivery of one of my favorite perf...</td>\n",
       "      <td>[got, delivery, one, favorite, perfumes, since...</td>\n",
       "      <td>[got, deliveri, one, favorit, perfum, sinc, br...</td>\n",
       "      <td>[got, one, broke, last, year, ago, today, smel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>one thing covid fucked up was me missing her b...</td>\n",
       "      <td>[one, thing, covid, fucked, missing, test, did...</td>\n",
       "      <td>[one, thing, covid, fuck, miss, test, didnt, c...</td>\n",
       "      <td>[one, thing, covid, miss, test, didnt, came, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>there are  letters in the new email handle for...</td>\n",
       "      <td>[letters, new, email, handle, communicating, c...</td>\n",
       "      <td>[letter, new, email, handl, commun, covid, iss...</td>\n",
       "      <td>[letter, new, covid, that, letter, alphabet, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>nice lil paid covid vacation</td>\n",
       "      <td>[nice, lil, paid, covid, vacation]</td>\n",
       "      <td>[nice, lil, paid, covid, vacat]</td>\n",
       "      <td>[nice, covid]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Content  \\\n",
       "0  love getting covid exposed by my idiot coworke...   \n",
       "1  hepatitis c virus reactivation following covid...   \n",
       "2  memorial day weekend was a dream\\n face the fa...   \n",
       "3  when you test positive for covid but find out ...   \n",
       "4   ppl in my office though i think it might be  ...   \n",
       "5  feels fitting to miss out on my last week of f...   \n",
       "6  just got a delivery of one of my favorite perf...   \n",
       "7  one thing covid fucked up was me missing her b...   \n",
       "8  there are  letters in the new email handle for...   \n",
       "9                       nice lil paid covid vacation   \n",
       "\n",
       "                                          text_token  \\\n",
       "0  [love, getting, covid, exposed, idiot, coworke...   \n",
       "1  [hepatitis, c, virus, reactivation, following,...   \n",
       "2  [memorial, day, weekend, dream, face, facts, d...   \n",
       "3  [test, positive, covid, find, offer, accepted,...   \n",
       "4  [ppl, office, though, think, might, bc, one, c...   \n",
       "5  [feels, fitting, miss, last, week, field, work...   \n",
       "6  [got, delivery, one, favorite, perfumes, since...   \n",
       "7  [one, thing, covid, fucked, missing, test, did...   \n",
       "8  [letters, new, email, handle, communicating, c...   \n",
       "9                 [nice, lil, paid, covid, vacation]   \n",
       "\n",
       "                                       Tweet_stemmed  \\\n",
       "0  [love, get, covid, expos, idiot, cowork, feel,...   \n",
       "1  [hepat, c, viru, reactiv, follow, covid, vacci...   \n",
       "2  [memori, day, weekend, dream, face, fact, dont...   \n",
       "3  [test, posit, covid, find, offer, accept, drea...   \n",
       "4  [ppl, offic, though, think, might, bc, one, cw...   \n",
       "5  [feel, fit, miss, last, week, field, work, job...   \n",
       "6  [got, deliveri, one, favorit, perfum, sinc, br...   \n",
       "7  [one, thing, covid, fuck, miss, test, didnt, c...   \n",
       "8  [letter, new, email, handl, commun, covid, iss...   \n",
       "9                    [nice, lil, paid, covid, vacat]   \n",
       "\n",
       "                                    Tweet_lemmatized  \n",
       "0  [love, get, covid, idiot, feel, sick, yesterda...  \n",
       "1  [follow, covid, infect, covid, manifest, loss,...  \n",
       "2  [day, weekend, dream, face, fact, dont, know, ...  \n",
       "3  [test, posit, covid, find, offer, accept, drea...  \n",
       "4     [though, think, might, one, covid, last, week]  \n",
       "5  [feel, fit, miss, last, week, field, work, job...  \n",
       "6  [got, one, broke, last, year, ago, today, smel...  \n",
       "7  [one, thing, covid, miss, test, didnt, came, b...  \n",
       "8  [letter, new, covid, that, letter, alphabet, t...  \n",
       "9                                      [nice, covid]  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Tweet_lemmatized'] = df['Tweet_lemmatized'].apply(lambda x: ' '.join([item for item in x if len(item)>2]))\n",
    "df['Tweet_lemmatized'] = df['Tweet_lemmatized'].apply(lambda x: [w for w in nltk.wordpunct_tokenize(x) if w.lower() in words or not w.isalpha()])\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d738e7a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[love, get, covid, idiot, feel, sick, yesterda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[follow, covid, infect, covid, manifest, loss,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[day, weekend, dream, face, fact, dont, know, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[test, posit, covid, find, offer, accept, drea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[though, think, might, one, covid, last, week]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Tweet_lemmatized\n",
       "0  [love, get, covid, idiot, feel, sick, yesterda...\n",
       "1  [follow, covid, infect, covid, manifest, loss,...\n",
       "2  [day, weekend, dream, face, fact, dont, know, ...\n",
       "3  [test, posit, covid, find, offer, accept, drea...\n",
       "4     [though, think, might, one, covid, last, week]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df = pd.DataFrame(df,columns=['Tweet_lemmatized'])\n",
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee69f12c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[love, get, covid, idiot, feel, sick, yesterda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[follow, covid, infect, covid, manifest, loss,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[day, weekend, dream, face, fact, dont, know, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[test, posit, covid, find, offer, accept, drea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[though, think, might, one, covid, last, week]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Content\n",
       "0  [love, get, covid, idiot, feel, sick, yesterda...\n",
       "1  [follow, covid, infect, covid, manifest, loss,...\n",
       "2  [day, weekend, dream, face, fact, dont, know, ...\n",
       "3  [test, posit, covid, find, offer, accept, drea...\n",
       "4     [though, think, might, one, covid, last, week]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "clean_df.columns = ['Content']\n",
    "clean_df.to_csv('clean_covid_600.csv',encoding='utf-8', index=False) \n",
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115287bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7ca128",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a1ef3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
